{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61fb5871-21de-4196-bb2c-70e232dd30ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__(): incompatible constructor arguments. The following argument types are supported:\n    1. DnnLib.Adam(learning_rate: typing.SupportsFloat = 0.001, beta1: typing.SupportsFloat = 0.9, beta2: typing.SupportsFloat = 0.999, epsilon: typing.SupportsFloat = 1e-08)\n\nInvoked with: kwargs: learning_rate=0.01, weight_decay=0.0001",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m layer2\u001b[38;5;241m.\u001b[39mweights \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m128\u001b[39m) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m0.01\u001b[39m\n\u001b[1;32m     20\u001b[0m layer2\u001b[38;5;241m.\u001b[39mbias \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m10\u001b[39m,))\n\u001b[0;32m---> 21\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m \u001b[43mDn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mAdam\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_rate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.01\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1e-4\u001b[39;49m\u001b[43m)\u001b[49m \n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m100\u001b[39m):\n\u001b[1;32m     24\u001b[0m     h1 \u001b[38;5;241m=\u001b[39m layer1\u001b[38;5;241m.\u001b[39mforward(datos)\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__(): incompatible constructor arguments. The following argument types are supported:\n    1. DnnLib.Adam(learning_rate: typing.SupportsFloat = 0.001, beta1: typing.SupportsFloat = 0.9, beta2: typing.SupportsFloat = 0.999, epsilon: typing.SupportsFloat = 1e-08)\n\nInvoked with: kwargs: learning_rate=0.01, weight_decay=0.0001"
     ]
    }
   ],
   "source": [
    "import DnnLib as Dn\n",
    "import numpy as np \n",
    "import json\n",
    "    \n",
    "def crear_modelo(input_dim=784, hidden_units=128, output_units=10):\n",
    "        layer1 = Dn.DenseLayer(input_dim, hidden_units, Dn.ActivationType.RELU)\n",
    "        layer2 = Dn.DenseLayer(hidden_units, output_units, Dn.ActivationType.SOFTMAX)\n",
    "        \n",
    "        return layer1, layer2\n",
    "    \n",
    "def calcular_accuracy(output, labels):\n",
    "        predictions = np.argmax(output, axis=1)\n",
    "        accuracy = np.mean(predictions == labels)\n",
    "        return accuracy\n",
    "    \n",
    "def entrenar_modelo(layer1, layer2, X_train, y_train, epochs=30, batch_size=64, lr=0.01):\n",
    "        optimizer = Dn.Adam(learning_rate=lr)\n",
    "        Mean_acc = []\n",
    "        for epoch in range(epochs):\n",
    "            \n",
    "            for i in range(0, X_train.shape[0], batch_size):\n",
    "                X_batch = X_train[i:i+batch_size]\n",
    "                y_batch = y_train[i:i+batch_size]\n",
    "                h1 = layer1.forward(X_batch)\n",
    "                output = layer2.forward(h1)\n",
    "                loss = Dn.cross_entropy(output, y_batch)\n",
    "                loss_grad = Dn.cross_entropy_gradient(output,y_batch)\n",
    "                grad2 = layer2.backward(loss_grad)\n",
    "                grad1 = layer1.backward(grad2)\n",
    "                optimizer.update(layer2)\n",
    "                optimizer.update(layer1)\n",
    "                \n",
    "            train_out = layer2.forward(layer1.forward(X_train))\n",
    "            train_loss = Dn.cross_entropy(train_out, y_train)\n",
    "            train_preds = np.argmax(train_out, axis=1)\n",
    "            train_acc = np.mean(train_preds == np.argmax(y_train, axis=1))\n",
    "            Mean_acc.append(train_acc)\n",
    "            if epoch % 5 == 0:\n",
    "                acc = np.mean(Mean_acc)\n",
    "                print(f\"Epoch {epoch}, \"\n",
    "                       f\"Train Loss: {train_loss:.6f},  Acc: {acc:.4f}, \")\n",
    "                Mean_acc.clear()\n",
    "        return layer1, layer2\n",
    "\n",
    "    \n",
    "    \n",
    "def exportar_modelo(layer1, layer2, filename=\"Modelo_fashion_MNIST.json\"):\n",
    "        model_dict = {\n",
    "            \"layers\": [\n",
    "                {\n",
    "                    \"type\": \"Dense\",\n",
    "                    \"input_dim\": layer1.weights.shape[1],\n",
    "                    \"output_dim\": layer1.weights.shape[0],\n",
    "                    \"activation\": \"ReLU\",\n",
    "                    \"weights\": layer1.weights.tolist(),\n",
    "                    \"bias\": layer1.bias.tolist()\n",
    "                },\n",
    "                {\n",
    "                    \"type\": \"Dense\",\n",
    "                    \"input_dim\": layer2.weights.shape[1],\n",
    "                    \"output_dim\": layer2.weights.shape[0],\n",
    "                    \"activation\": \"Softmax\",\n",
    "                    \"weights\": layer2.weights.tolist(),\n",
    "                    \"bias\": layer2.bias.tolist()\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "        with open(filename, \"w\") as f:\n",
    "            json.dump(model_dict, f, indent=4)\n",
    "        print(f\"Modelo exportado\")\n",
    "    \n",
    "def cargar_modelo(filename=\"modelo.json\"):\n",
    "        with open(filename, \"r\") as f:\n",
    "            model_dict = json.load(f)\n",
    "    \n",
    "        layer1_info = model_dict[\"layers\"][0]\n",
    "        layer2_info = model_dict[\"layers\"][1]\n",
    "    \n",
    "        layer1 = Dn.DenseLayer(layer1_info[\"input_dim\"], layer1_info[\"output_dim\"], Dn.ActivationType.RELU)\n",
    "        layer1.weights = np.array(layer1_info[\"weights\"])\n",
    "        layer1.bias = np.array(layer1_info[\"bias\"])\n",
    "        \n",
    "        layer2 = Dn.DenseLayer(layer2_info[\"input_dim\"], layer2_info[\"output_dim\"], Dn.ActivationType.SOFTMAX)\n",
    "        layer2.weights = np.array(layer2_info[\"weights\"])\n",
    "        layer2.bias = np.array(layer2_info[\"bias\"])\n",
    "    \n",
    "        print(f\"Modelo cargado\")\n",
    "        return layer1, layer2\n",
    "\n",
    "    \n",
    "def evaluar_modelo(layer1, layer2,):\n",
    "    Eval = np.load(\"mnist_test.npz\")\n",
    "    images_eval = Eval[\"images\"]\n",
    "    labels_eval = Eval[\"labels\"]\n",
    "    h1 = layer1.forward(datos_eval)\n",
    "    output = layer2.forward(h1)\n",
    "    predictions = np.argmax(output, axis=1)\n",
    "    accuracy = np.mean(predictions== labels_eval)\n",
    "    print(\"Precision del modelo Testeada: \",accuracy)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    data = np.load(\"mnist_train.npz\")\n",
    "    images = data[\"images\"] \n",
    "    labels = data[\"labels\"]\n",
    "    datos = (images / 255.0).reshape(images.shape[0], -1)\n",
    "    y_train_onehot = np.eye(10)[labels]\n",
    "\n",
    "    layer1, layer2 = crear_modelo()\n",
    "    layer1, layer2 = entrenar_modelo(layer1, layer2, datos, y_train_onehot)\n",
    "    exportar_modelo(layer1, layer2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "395d931d-b391-490c-9a03-0fb532c00c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
